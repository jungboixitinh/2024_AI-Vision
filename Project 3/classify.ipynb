{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"elapsed":27383,"status":"error","timestamp":1720753909219,"user":{"displayName":"oldmansky boost","userId":"05431798034929600082"},"user_tz":-420},"id":"gVa-a99769OY","outputId":"be4deeea-98ea-451a-a775-fc473fecc998"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n","goldfish (99.98%)\n"]}],"source":["from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","from keras.applications.vgg16 import decode_predictions\n","from keras.applications.vgg16 import VGG16\n","\n","\n","# load the model\n","model = VGG16()\n","\n","# load an image from file\n","image = load_img('C:/Users/ACER/source/2024_AI-Vision/Project 3/test image/fish.jpg', target_size=(224, 224))\n","\n","# convert the image pixels to a numpy array\n","image = img_to_array(image)\n","\n","# reshape data for the model\n","# batch size - height - width - channels\n","image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\n","# prepare the image for the VGG model\n","image = preprocess_input(image)\n","\n","# predict the probability across all output classes\n","yhat = model.predict(image)\n","\n","# convert the probabilities to class labels\n","label = decode_predictions(yhat)\n","\n","# retrieve the most likely result, e.g. highest probability\n","label = label[0][0]\n","\n","# print the classification\n","print('%s (%.2f%%)' % (label[1], label[2]*100))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
